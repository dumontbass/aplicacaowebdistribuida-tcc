<?xml version="1.0" encoding="UTF-8" standalone="no"?><html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Chapter 5. Consistency</title>
<link href="9780133036121.css" rel="stylesheet" type="text/css"/>
<link href="page-template.xpgt" rel="stylesheet" type="application/vnd.adobe-page-template+xml"/>
<meta name="Adept.resource" value="urn:uuid:612fcd70-0110-46e1-b1de-b4c342e334cd"/>
</head>
<body>
<h2 id="ch05"><a id="page_47"/>Chapter 5. Consistency</h2>
<p class="noindent">One of the biggest changes from a centralized relational database to a cluster-oriented NoSQL database is in how you think about consistency. Relational databases try to exhibit <strong>strong consistency</strong> by avoiding all the various inconsistencies that we’ll shortly be discussing. Once you start looking at the NoSQL world, phrases such as “CAP theorem” and “eventual consistency” appear, and as soon as you start building something you have to think about what sort of consistency you need for your system.</p>
<p class="indent">Consistency comes in various forms, and that one word covers a myriad of ways errors can creep into your life. So we’re going to begin by talking about the various shapes consistency can take. After that we’ll discuss why you may want to relax consistency (and its big sister, durability).</p>
<h3 id="ch05lev1sec1">5.1. Update Consistency</h3>
<p class="noindent">We’ll begin by considering updating a telephone number. Coincidentally, Martin and Pramod are looking at the company website and notice that the phone number is out of date. Implausibly, they both have update access, so they both go in at the same time to update the number. To make the example interesting, we’ll assume they update it slightly differently, because each uses a slightly different format. This issue is called a <strong>write-write conflict</strong>: two people updating the same data item at the same time.</p>
<p class="indent">When the writes reach the server, the server will <strong>serialize</strong> them—decide to apply one, then the other. Let’s assume it uses alphabetical order and picks Martin’s update first, then Pramod’s. Without any concurrency control, Martin’s update would be applied and immediately overwritten by Pramod’s. In this case Martin’s is a <strong>lost update</strong>. Here the lost update is not a big problem, but often it is. We see this as a failure of consistency because Pramod’s update was based on the state before Martin’s update, yet was applied after it.</p>
<p class="indent"><a id="page_48"/>Approaches for maintaining consistency in the face of concurrency are often described as pessimistic or optimistic. A <strong>pessimistic</strong> approach works by preventing conflicts from occurring; an <strong>optimistic</strong> approach lets conflicts occur, but detects them and takes action to sort them out. For update conflicts, the most common pessimistic approach is to have write locks, so that in order to change a value you need to acquire a lock, and the system ensures that only one client can get a lock at a time. So Martin and Pramod would both attempt to acquire the write lock, but only Martin (the first one) would succeed. Pramod would then see the result of Martin’s write before deciding whether to make his own update.</p>
<p class="indent">A common optimistic approach is a <strong>conditional update</strong> where any client that does an update tests the value just before updating it to see if it’s changed since his last read. In this case, Martin’s update would succeed but Pramod’s would fail. The error would let Pramod know that he should look at the value again and decide whether to attempt a further update.</p>
<p class="indent">Both the pessimistic and optimistic approaches that we’ve just described rely on a consistent serialization of the updates. With a single server, this is obvious—it has to choose one, then the other. But if there’s more than one server, such as with peer-to-peer replication, then two nodes might apply the updates in a different order, resulting in a different value for the telephone number on each peer. Often, when people talk about concurrency in distributed systems, they talk about sequential consistency—ensuring that all nodes apply operations in the same order.</p>
<p class="indent">There is another optimistic way to handle a write-write conflict—save both updates and record that they are in conflict. This approach is familiar to many programmers from version control systems, particularly distributed version control systems that by their nature will often have conflicting commits. The next step again follows from version control: You have to merge the two updates somehow. Maybe you show both values to the user and ask them to sort it out—this is what happens if you update the same contact on your phone and your computer. Alternatively, the computer may be able to perform the merge itself; if it was a phone formatting issue, it may be able to realize that and apply the new number with the standard format. Any automated merge of write-write conflicts is highly domain-specific and needs to be programmed for each particular case.</p>
<p class="indent">Often, when people first encounter these issues, their reaction is to prefer pessimistic concurrency because they are determined to avoid conflicts. While in some cases this is the right answer, there is always a tradeoff. Concurrent programming involves a fundamental tradeoff between safety (avoiding errors such as update conflicts) and liveness (responding quickly to clients). Pessimistic approaches often severely degrade the responsiveness of a system to the degree that it becomes unfit for its purpose. This problem is made worse by the danger of errors—pessimistic concurrency often leads to deadlocks, which are hard to prevent and debug.</p>
<p class="indent"><a id="page_49"/>Replication makes it much more likely to run into write-write conflicts. If different nodes have different copies of some data which can be independently updated, then you’ll get conflicts unless you take specific measures to avoid them. Using a single node as the target for all writes for some data makes it much easier to maintain update consistency. Of the distribution models we discussed earlier, all but peer-to-peer replication do this.</p>
<h3 id="ch05lev1sec2">5.2. Read Consistency</h3>
<p class="noindent">Having a data store that maintains update consistency is one thing, but it doesn’t guarantee that readers of that data store will always get consistent responses to their requests. Let’s imagine we have an order with line items and a shipping charge. The shipping charge is calculated based on the line items in the order. If we add a line item, we thus also need to recalculate and update the shipping charge. In a relational database, the shipping charge and line items will be in separate tables. The danger of inconsistency is that Martin adds a line item to his order, Pramod then reads the line items and shipping charge, and then Martin updates the shipping charge. This is an <strong>inconsistent read</strong> or <strong>read-write conflict</strong>: In <a href="#ch05fig01">Figure 5.1</a> Pramod has done a read in the middle of Martin’s write.</p>
<div class="image"><a id="ch05fig01"/><img alt="Image" src="graphics/05fig01.jpg"/></div>
<p class="fig-caption">Figure 5.1. A read-write conflict in logical consistency</p>
<p class="indent"><a id="page_50"/>We refer to this type of consistency as <strong>logical consistency</strong>: ensuring that different data items make sense together. To avoid a logically inconsistent read-write conflict, relational databases support the notion of transactions. Providing Martin wraps his two writes in a transaction, the system guarantees that Pramod will either read both data items before the update or both after the update.</p>
<p class="indent">A common claim we hear is that NoSQL databases don’t support transactions and thus can’t be consistent. Such claim is mostly wrong because it glosses over lots of important details. Our first clarification is that any statement about lack of transactions usually only applies to some NoSQL databases, in particular the aggregate-oriented ones. In contrast, graph databases tend to support ACID transactions just the same as relational databases.</p>
<p class="indent">Secondly, aggregate-oriented databases do support atomic updates, but only within a single aggregate. This means that you will have logical consistency within an aggregate but not between aggregates. So in the example, you could avoid running into that inconsistency if the order, the delivery charge, and the line items are all part of a single order aggregate.</p>
<p class="indent">Of course not all data can be put in the same aggregate, so any update that affects multiple aggregates leaves open a time when clients could perform an inconsistent read. The length of time an inconsistency is present is called the <strong>inconsistency window</strong>. A NoSQL system may have a quite short inconsistency window: As one data point, Amazon’s documentation says that the inconsistency window for its SimpleDB service is usually less than a second.</p>
<p class="indent">This example of a logically inconsistent read is the classic example that you’ll see in any book that touches database programming. Once you introduce replication, however, you get a whole new kind of inconsistency. Let’s imagine there’s one last hotel room for a desirable event. The hotel reservation system runs on many nodes. Martin and Cindy are a couple considering this room, but they are discussing this on the phone because Martin is in London and Cindy is in Boston. Meanwhile Pramod, who is in Mumbai, goes and books that last room. That updates the replicated room availability, but the update gets to Boston quicker than it gets to London. When Martin and Cindy fire up their browsers to see if the room is available, Cindy sees it booked and Martin sees it free. This is another inconsistent read—but it’s a breach of a different form of consistency we call <strong>replication consistency</strong>: ensuring that the same data item has the same value when read from different replicas (see <a href="#ch05fig02">Figure 5.2</a>).</p>
<div class="image"><a id="page_51"/><a id="ch05fig02"/><img alt="Image" src="graphics/05fig02.jpg"/></div>
<p class="fig-caption">Figure 5.2. An example of replication inconsistency</p>
<p class="indent">Eventually, of course, the updates will propagate fully, and Martin will see the room is fully booked. Therefore this situation is generally referred to as <strong>eventually consistent</strong>, meaning that at any time nodes may have replication inconsistencies but, if there are no further updates, eventually all nodes will be updated to the same value. Data that is out of date is generally referred to as <strong>stale</strong>, which reminds us that a cache is another form of replication—essentially following the master-slave distribution model.</p>
<p class="indent">Although replication consistency is independent from logical consistency, replication can exacerbate a logical inconsistency by lengthening its inconsistency window. Two different updates on the master may be performed in rapid succession, leaving an inconsistency window of milliseconds. But delays in networking could mean that the same inconsistency window lasts for much longer on a slave.</p>
<p class="indent">Consistency guarantees aren’t something that’s global to an application. You can usually specify the level of consistency you want with individual requests. This allows you to use weak consistency most of the time when it isn’t an issue, but request strong consistency when it is.</p>
<p class="indent">The presence of an inconsistency window means that different people will see different things at the same time. If Martin and Cindy are looking at rooms while on a transatlantic call, it can cause confusion. It’s more common for users to act independently, and then this is not a problem. But inconsistency windows can be particularly problematic when you get inconsistencies with yourself. Consider the example of posting comments on a blog entry. Few people are going to worry about inconsistency windows of even a few minutes while people are typing in their latest thoughts. Often, systems handle the load of such sites by running on a cluster and load-balancing incoming requests to different nodes. Therein lies a danger: You may post a message using one node, then refresh your browser, but the refresh goes to a different node which hasn’t received your post yet—and it looks like your post was lost.</p>
<p class="indent"><a id="page_52"/>In situations like this, you can tolerate reasonably long inconsistency windows, but you need <strong>read-your-writes consistency</strong> which means that, once you’ve made an update, you’re guaranteed to continue seeing that update. One way to get this in an otherwise eventually consistent system is to provide <strong>session consistency</strong>: Within a user’s session there is read-your-writes consistency. This does mean that the user may lose that consistency should their session end for some reason or should the user access the same system simultaneously from different computers, but these cases are relatively rare.</p>
<p class="indent">There are a couple of techniques to provide session consistency. A common way, and often the easiest way, is to have a <strong>sticky session</strong>: a session that’s tied to one node (this is also called <strong>session affinity</strong>). A sticky session allows you to ensure that as long as you keep read-your-writes consistency on a node, you’ll get it for sessions too. The downside is that sticky sessions reduce the ability of the load balancer to do its job.</p>
<p class="indent">Another approach for session consistency is to use version stamps (“<a href="ch06.html#ch06">Version Stamps</a>,” p. <a href="ch06.html#page_61">61</a>) and ensure every interaction with the data store includes the latest version stamp seen by a session. The server node must then ensure that it has the updates that include that version stamp before responding to a request.</p>
<p class="indent">Maintaining session consistency with sticky sessions and master-slave replication can be awkward if you want to read from the slaves to improve read performance but still need to write to the master. One way of handling this is for writes to be sent the slave, who then takes responsibility for forwarding them to the master while maintaining session consistency for its client. Another approach is to switch the session to the master temporarily when doing a write, just long enough that reads are done from the master until the slaves have caught up with the update.</p>
<p class="indent">We’re talking about replication consistency in the context of a data store, but it’s also an important factor in overall application design. Even a simple database system will have lots of occasions where data is presented to a user, the user cogitates, and then updates that data. It’s usually a bad idea to keep a transaction open during user interaction because there’s a real danger of conflicts when the user tries to make her update, which leads to such approaches as offline locks <a href="bib01.html#bib_26">[Fowler PoEAA]</a>.</p>
<h3 id="ch05lev1sec3">5.3. Relaxing Consistency</h3>
<p class="noindent">Consistency is a Good Thing—but, sadly, sometimes we have to sacrifice it. It is always possible to design a system to avoid inconsistencies, but often impossible to do so without making unbearable sacrifices in other characteristics of the system. As a result, we often have to tradeoff consistency for something else. While some architects see this as a disaster, we see it as part of the inevitable <a id="page_53"/>tradeoffs involved in system design. Furthermore, different domains have different tolerances for inconsistency, and we need to take this tolerance into account as we make our decisions.</p>
<p class="indent">Trading off consistency is a familiar concept even in single-server relational database systems. Here, our principal tool to enforce consistency is the transaction, and transactions can provide strong consistency guarantees. However, transaction systems usually come with the ability to relax isolation levels, allowing queries to read data that hasn’t been committed yet, and in practice we see most applications relax consistency down from the highest isolation level (serialized) in order to get effective performance. We most commonly see people using the read-committed transaction level, which eliminates some read-write conflicts but allows others.</p>
<p class="indent">Many systems forgo transactions entirely because the performance impact of transactions is too high. We’ve seen this in a couple different ways. On a small scale, we saw the popularity of MySQL during the days when it didn’t support transactions. Many websites liked the high speed of MySQL and were prepared to live without transactions. At the other end of the scale, some very large websites, such as eBay <a href="bib01.html#bib_56">[Pritchett]</a>, have had to forgo transactions in order to perform acceptably—this is particularly true when you need to introduce sharding. Even without these constraints, many application builders need to interact with remote systems that can’t be properly included within a transaction boundary, so updating outside of transactions is a quite common occurrence for enterprise applications.</p>
<h4 id="ch05lev2sec1">5.3.1. The CAP Theorem</h4>
<p class="noindent">In the NoSQL world it’s common to refer to the CAP theorem as the reason why you may need to relax consistency. It was originally proposed by Eric Brewer in 2000 <a href="bib01.html#bib_08">[Brewer]</a> and given a formal proof by Seth Gilbert and Nancy Lynch <a href="bib01.html#bib_42">[Lynch and Gilbert]</a> a couple of years later. (You may also hear this referred to as Brewer’s Conjecture.)</p>
<p class="indent">The basic statement of the CAP theorem is that, given the three properties of Consistency, Availability, and Partition tolerance, you can only get two. Obviously this depends very much on how you define these three properties, and differing opinions have led to several debates on what the real consequences of the CAP theorem are.</p>
<p class="indent">Consistency is pretty much as we’ve defined it so far. <strong>Availability</strong> has a particular meaning in the context of CAP—it means that if you can talk to a node in the cluster, it can read and write data. That’s subtly different from the usual meaning, which we’ll explore later. <strong>Partition tolerance</strong> means that the cluster can survive communication breakages in the cluster that separate the cluster into multiple partitions unable to communicate with each other (situation known as a <strong>split brain</strong>, see <a href="#ch05fig03">Figure 5.3</a>).</p>
<div class="image"><a id="page_54"/><a id="ch05fig03"/><img alt="Image" src="graphics/05fig03.jpg"/></div>
<p class="fig-caption">Figure 5.3. With two breaks in the communication lines, the network partitions into two groups.</p>
<p class="indent">A single-server system is the obvious example of a CA system—a system that has Consistency and Availability but not Partition tolerance. A single machine can’t partition, so it does not have to worry about partition tolerance. There’s only one node—so if it’s up, it’s available. Being up and keeping consistency is reasonable. This is the world that most relational database systems live in.</p>
<p class="indent">It is theoretically possible to have a CA cluster. However, this would mean that if a partition ever occurs in the cluster, all the nodes in the cluster would go down so that no client can talk to a node. By the usual definition of “available,” this would mean a lack of availability, but this is where CAP’s special usage of “availability” gets confusing. CAP defines “availability” to mean “every request received by a nonfailing node in the system must result in a response” <a href="bib01.html#bib_42">[Lynch and Gilbert]</a>. So a failed, unresponsive node doesn’t infer a lack of CAP availability.</p>
<p class="indent">This does imply that you can build a CA cluster, but you have to ensure it will only partition rarely and completely. This can be done, at least within a data center, but it’s usually prohibitively expensive. Remember that in order to bring down all the nodes in a cluster on a partition, you also have to detect the partition in a timely manner—which itself is no small feat.</p>
<p class="indent">So clusters have to be tolerant of network partitions. And here is the real point of the CAP theorem. Although the CAP theorem is often stated as “you can only get two out of three,” in practice what it’s saying is that in a system that may suffer partitions, as distributed system do, you have to trade off consistency <a id="page_55"/>versus availability. This isn’t a binary decision; often, you can trade off a little consistency to get some availability. The resulting system would be neither perfectly consistent nor perfectly available—but would have a combination that is reasonable for your particular needs.</p>
<p class="indent">An example should help illustrate this. Martin and Pramod are both trying to book the last hotel room on a system that uses peer-to-peer distribution with two nodes (London for Martin and Mumbai for Pramod). If we want to ensure consistency, then when Martin tries to book his room on the London node, that node must communicate with the Mumbai node before confirming the booking. Essentially, both nodes must agree on the serialization of their requests. This gives us consistency—but should the network link break, then neither system can book any hotel room, sacrificing availability.</p>
<p class="indent">One way to improve availability is to designate one node as the master for a particular hotel and ensure all bookings are processed by that master. Should that master be Mumbai, then Mumbai can still process hotel bookings for that hotel and Pramod will get the last room. If we use master-slave replication, London users can see the inconsistent room information but cannot make a booking and thus cause an update inconsistency. However, users expect that it could happen in this situation—so, again, the compromise works for this particular use case.</p>
<p class="indent">This improves the situation, but we still can’t book a room on the London node for the hotel whose master is in Mumbai if the connection goes down. In CAP terminology, this is a failure of availability in that Martin can talk to the London node but the London node cannot update the data. To gain more availability, we might allow both systems to keep accepting hotel reservations even if the network link breaks down. The danger here is that Martin and Pramod book the last hotel room. However, depending on how this hotel operates, that may be fine. Often, travel companies tolerate a certain amount of overbooking in order to cope with no-shows. Conversely, some hotels always keep a few rooms clear even when they are fully booked, in order to be able to swap a guest out of a room with problems or to accommodate a high-status late booking. Some might even cancel the booking with an apology once they detected the conflict—reasoning that the cost of that is less than the cost of losing bookings on network failures.</p>
<p class="indent">The classic example of allowing inconsistent writes is the shopping cart, as discussed in Dynamo <a href="bib01.html#bib_02">[Amazon’s Dynamo]</a>. In this case you are always allowed to write to your shopping cart, even if network failures mean you end up with multiple shopping carts. The checkout process can merge the two shopping carts by putting the union of the items from the carts into a single cart and returning that. Almost always that’s the correct answer—but if not, the user gets the opportunity to look at the cart before completing the order.</p>
<p class="indent">The lesson here is that although most software developers treat update consistency as The Way Things Must Be, there are cases where you can deal gracefully with inconsistent answers to requests. These situations are closely tied to the <a id="page_56"/>domain and require domain knowledge to know how to resolve. Thus you can’t usually look to solve them purely within the development team—you have to talk to domain experts. If you can find a way to handle inconsistent updates, this gives you more options to increase availability and performance. For a shopping cart, it means that shoppers can always shop, and do so quickly. And as Patriotic Americans, we know how vital it is to support Our Retail Destiny.</p>
<p class="indent">A similar logic applies to read consistency. If you are trading financial instruments over a computerized exchange, you may not be able to tolerate any data that isn’t right up to date. However, if you are posting a news item to a media website, you may be able to tolerate old pages for minutes.</p>
<p class="indent">In these cases you need to know how tolerant you are of stale reads, and how long the inconsistency window can be—often in terms of the average length, worst case, and some measure of the distribution for the lengths. Different data items may have different tolerances for staleness, and thus may need different settings in your replication configuration.</p>
<p class="indent">Advocates of NoSQL often say that instead of following the ACID properties of relational transactions, NoSQL systems follow the BASE properties (Basically Available, Soft state, Eventual consistency) <a href="bib01.html#bib_08">[Brewer]</a>. Although we feel we ought to mention the BASE acronym here, we don’t think it’s very useful. The acronym is even more contrived than ACID, and neither “basically available” nor “soft state” have been well defined. We should also stress that when Brewer introduced the notion of BASE, he saw the tradeoff between ACID and BASE as a spectrum, not a binary choice.</p>
<p class="indent">We’ve included this discussion of the CAP theorem because it’s often used (and abused) when talking about the tradeoffs involving consistency in distributed databases. However, it’s usually better to think not about the tradeoff between consistency and availability but rather between consistency and <em>latency</em>. We can summarize much of the discussion about consistency in distribution by saying that we can improve consistency by getting more nodes involved in the interaction, but each node we add increases the response time of that interaction. We can then think of availability as the limit of latency that we’re prepared to tolerate; once latency gets too high, we give up and treat the data as unavailable—which neatly fits its definition in the context of CAP.</p>
<h3 id="ch05lev1sec4">5.4. Relaxing Durability</h3>
<p class="noindent">So far we’ve talked about consistency, which is most of what people mean when they talk about the ACID properties of database transactions. The key to Consistency is serializing requests by forming Atomic, Isolated work units. But most people would scoff at relaxing durability—after all, what is the point of a data store if it can lose updates?</p>
<p class="indent"><a id="page_57"/>As it turns out, there are cases where you may want to trade off some durability for higher performance. If a database can run mostly in memory, apply updates to its in-memory representation, and periodically flush changes to disk, then it may be able to provide substantially higher responsiveness to requests. The cost is that, should the server crash, any updates since the last flush will be lost.</p>
<p class="indent">One example of where this tradeoff may be worthwhile is storing user-session state. A big website may have many users and keep temporary information about what each user is doing in some kind of session state. There’s a lot of activity on this state, creating lots of demand, which affects the responsiveness of the website. The vital point is that losing the session data isn’t too much of a tragedy—it will create some annoyance, but maybe less than a slower website would cause. This makes it a good candidate for nondurable writes. Often, you can specify the durability needs on a call-by-call basis, so that more important updates can force a flush to disk.</p>
<p class="indent">Another example of relaxing durability is capturing telemetric data from physical devices. It may be that you’d rather capture data at a faster rate, at the cost of missing the last updates should the server go down.</p>
<p class="indent">Another class of durability tradeoffs comes up with replicated data. A failure of <strong>replication durability</strong> occurs when a node processes an update but fails before that update is replicated to the other nodes. A simple case of this may happen if you have a master-slave distribution model where the slaves appoint a new master automatically should the existing master fail. If a master does fail, any writes not passed onto the replicas will effectively become lost. Should the master come back online, those updates will conflict with updates that have happened since. We think of this as a durability problem because you think your update has succeeded since the master acknowledged it, but a master node failure caused it to be lost.</p>
<p class="indent">If you’re sufficiently confident in bringing the master back online rapidly, this is a reason not to auto-failover to a slave. Otherwise, you can improve replication durability by ensuring that the master waits for some replicas to acknowledge the update before the master acknowledges it to the client. Obviously, however, that will slow down updates and make the cluster unavailable if slaves fail—so, again, we have a tradeoff, depending upon how vital durability is. As with basic durability, it’s useful for individual calls to indicate what level of durability they need.</p>
<h3 id="ch05lev1sec5">5.5. Quorums</h3>
<p class="noindent">When you’re trading off consistency or durability, it’s not an all or nothing proposition. The more nodes you involve in a request, the higher is the chance of avoiding an inconsistency. This naturally leads to the question: How many nodes need to be involved to get strong consistency?</p>
<p class="indent"><a id="page_58"/>Imagine some data replicated over three nodes. You don’t need all nodes to acknowledge a write to ensure strong consistency; all you need is two of them—a majority. If you have conflicting writes, only one can get a majority. This is referred to as a <strong>write quorum</strong> and expressed in a slightly pretentious inequality of <code>W &gt; N/2</code>, meaning the number of nodes participating in the write (<code>W</code>) must be more than the half the number of nodes involved in replication (<code>N</code>). The number of replicas is often called the <strong>replication factor</strong>.</p>
<p class="indent">Similarly to the write quorum, there is the notion of read quorum: How many nodes you need to contact to be sure you have the most up-to-date change. The read quorum is a bit more complicated because it depends on how many nodes need to confirm a write.</p>
<p class="indent">Let’s consider a replication factor of 3. If all writes need two nodes to confirm (<code>W = 2</code>) then we need to contact at least two nodes to be sure we’ll get the latest data. If, however, writes are only confirmed by a single node (<code>W = 1</code>) we need to talk to all three nodes to be sure we have the latest updates. In this case, since we don’t have a write quorum, we may have an update conflict, but by contacting enough readers we can be sure to detect it. Thus we can get strongly consistent reads even if we don’t have strong consistency on our writes.</p>
<p class="indent">This relationship between the number of nodes you need to contact for a read (<code>R</code>), those confirming a write (<code>W</code>), and the replication factor (<code>N</code>) can be captured in an inequality: You can have a strongly consistent read if <code>R + W &gt; N</code>.</p>
<p class="indent">These inequalities are written with a peer-to-peer distribution model in mind. If you have a master-slave distribution, you only have to write to the master to avoid write-write conflicts, and similarly only read from the master to avoid read-write conflicts. With this notation, it is common to confuse the number of nodes in the cluster with the replication factor, but these are often different. I may have 100 nodes in my cluster, but only have a replication factor of 3, with most of the distribution occurring due to sharding.</p>
<p class="indent">Indeed most authorities suggest that a replication factor of 3 is enough to have good resilience. This allows a single node to fail while still maintaining quora for reads and writes. If you have automatic rebalancing, it won’t take too long for the cluster to create a third replica, so the chances of losing a second replica before a replacement comes up are slight.</p>
<p class="indent">The number of nodes participating in an operation can vary with the operation. When writing, we might require quorum for some types of updates but not others, depending on how much we value consistency and availability. Similarly, a read that needs speed but can tolerate staleness should contact less nodes.</p>
<p class="indent">Often you may need to take both into account. If you need fast, strongly consistent reads, you could require writes to be acknowledged by all the nodes, thus allowing reads to contact only one (<code>N = 3</code>, <code>W = 3</code>, <code>R = 1</code>). That would mean that your writes are slow, since they have to contact all three nodes, and you would <a id="page_59"/>not be able to tolerate losing a node. But in some circumstances that may be the tradeoff to make.</p>
<p class="indent">The point to all of this is that you have a range of options to work with and can choose which combination of problems and advantages to prefer. Some writers on NoSQL talk about a simple tradeoff between consistency and availability; we hope you now realize that it’s more flexible—and more complicated—than that.</p>
<h3 id="ch05lev1sec6">5.6. Further Reading</h3>
<p class="noindent">There are all sorts of interesting blog posts and papers on the Internet about consistency in distributed systems, but the most helpful source for us was <a href="bib01.html#bib_64">[Tanenbaum and Van Steen]</a>. It does an excellent job of organizing much of the fundamentals of distributed systems and is the best place to go if you’d like to delve deeper than we have in this chapter.</p>
<p class="indent">As we were finishing this book, <em>IEEE Computer</em> had a special issue [IEEE Computer Feb 2012] on the growing influence of the CAP theorem, which is a helpful source of further clarification for this topic.</p>
<h3 id="ch05lev1sec7">5.7. Key Points</h3>
<p class="indenthangingB">• Write-write conflicts occur when two clients try to write the same data at the same time. Read-write conflicts occur when one client reads inconsistent data in the middle of another client’s write.</p>
<p class="indenthangingB">• Pessimistic approaches lock data records to prevent conflicts. Optimistic approaches detect conflicts and fix them.</p>
<p class="indenthangingB">• Distributed systems see read-write conflicts due to some nodes having received updates while other nodes have not. Eventual consistency means that at some point the system will become consistent once all the writes have propagated to all the nodes.</p>
<p class="indenthangingB">• Clients usually want read-your-writes consistency, which means a client can write and then immediately read the new value. This can be difficult if the read and the write happen on different nodes.</p>
<p class="indenthangingB">• To get good consistency, you need to involve many nodes in data operations, but this increases latency. So you often have to trade off consistency versus latency.</p>
<p class="indenthangingB"><a id="page_60"/>• The CAP theorem states that if you get a network partition, you have to trade off availability of data versus consistency.</p>
<p class="indenthangingB">• Durability can also be traded off against latency, particularly if you want to survive failures with replicated data.</p>
<p class="indenthangingB">• You do not need to contact all replicants to preserve strong consistency with replication; you just need a large enough quorum.</p>
</body>
</html>